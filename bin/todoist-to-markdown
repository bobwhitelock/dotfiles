#!/usr/bin/env python3

import os
import sys
import json
from urllib.request import Request, urlopen
from urllib.parse import urlencode
from urllib.error import URLError, HTTPError
import hashlib
from concurrent.futures import ThreadPoolExecutor, as_completed

# TODO BW 2025-09-20: Comments (and maybe descriptions?) are handled badly,
# multiline content will start on one line but then appear as if it is a new
# task/section on subsequent lines
# TODO BW 2025-09-20: If an attachment fails to attach, this script ends up
# downloading the Todoist login page for that attachment instead.

def get_todoist_api_token():
    """Get the Todoist API token from environment variable."""
    token = os.environ.get('TODOIST_API_TOKEN')
    if not token:
        print("Error: TODOIST_API_TOKEN environment variable not set", file=sys.stderr)
        sys.exit(1)
    return token


def make_sync_request(resource_types, token):
    """Make a sync request to the Todoist API v1."""
    url = "https://api.todoist.com/api/v1/sync"
    data = urlencode({
        'sync_token': '*',
        'resource_types': json.dumps(resource_types)
    })

    req = Request(url, data.encode('utf-8'))
    req.add_header('Authorization', f'Bearer {token}')
    req.add_header('Content-Type', 'application/x-www-form-urlencoded')
    req.add_header('User-Agent', 'bob.whitelock1@gmail.com')

    try:
        with urlopen(req) as response:
            return json.loads(response.read().decode('utf-8'))
    except HTTPError as e:
        if e.code == 429:
            retry_after = e.headers.get('Retry-After')
            if retry_after:
                print(f"Rate limit exceeded (429). Retry after {retry_after} seconds.", file=sys.stderr)
            else:
                print("Rate limit exceeded (429). No retry-after header provided.", file=sys.stderr)
        else:
            print(f"HTTP Error {e.code}: {e.reason}", file=sys.stderr)
        sys.exit(1)
    except URLError as e:
        print(f"URL Error: {e.reason}", file=sys.stderr)
        sys.exit(1)
    except json.JSONDecodeError as e:
        print(f"JSON decode error: {e}", file=sys.stderr)
        sys.exit(1)



def get_all_tasks_and_comments(token):
    """Get all tasks, comments, labels, and sections from Todoist."""
    print("Getting all tasks, comments, labels, and sections...", file=sys.stderr)
    sync_data = make_sync_request(['items', 'notes', 'labels', 'sections'], token)
    all_tasks = sync_data.get('items', [])
    all_comments = sync_data.get('notes', [])
    all_labels = sync_data.get('labels', [])
    all_sections = sync_data.get('sections', [])
    return all_tasks, all_comments, all_labels, all_sections


def filter_project_tasks_and_comments(project_id, all_tasks, all_comments, all_labels, all_sections):
    """Filter tasks, comments, labels, and sections for a specific project from pre-fetched data."""
    # Filter tasks for the specific project
    project_tasks = [task for task in all_tasks if task['project_id'] == project_id]

    # Filter comments for tasks in this project
    task_ids = {task['id'] for task in project_tasks}
    project_comments = [comment for comment in all_comments if comment.get('item_id') in task_ids]

    # Filter sections for this project
    project_sections = [section for section in all_sections if section['project_id'] == project_id]

    return project_tasks, project_comments, all_labels, project_sections


def build_task_hierarchy(tasks, comments, sections):
    """Build a hierarchical structure of tasks with comments, organized by sections."""
    task_dict = {task['id']: task for task in tasks}
    section_dict = {section['id']: section for section in sections}

    # Add children and comments lists to each task
    for task in tasks:
        task['children'] = []
        task['comments'] = []

    # Associate comments with tasks
    for comment in comments:
        item_id = comment.get('item_id')
        if item_id and item_id in task_dict:
            task_dict[item_id]['comments'].append(comment)

    # Build the hierarchy
    root_tasks = []
    for task in tasks:
        if task.get('parent_id'):
            parent = task_dict.get(task['parent_id'])
            if parent:
                parent['children'].append(task)
        else:
            root_tasks.append(task)

    # Group root tasks by section
    sections_with_tasks = {}
    tasks_without_section = []

    for task in root_tasks:
        section_id = task.get('section_id')
        if section_id and section_id in section_dict:
            section_name = section_dict[section_id]['name']
            if section_name not in sections_with_tasks:
                sections_with_tasks[section_name] = []
            sections_with_tasks[section_name].append(task)
        else:
            tasks_without_section.append(task)

    return sections_with_tasks, tasks_without_section


def format_priority(priority):
    """Format task priority as !!1 through !!4."""
    if priority and priority > 1:
        return f"!!{priority}"
    return ""


def format_labels(label_names):
    """Format task labels as @label1 @label2."""
    if not label_names:
        return ""
    # Labels are already strings, just add @ prefix
    labels = [f"@{label}" for label in label_names]
    return " ".join(labels)


def format_date(date_str):
    """Format date from ISO format to yyyy-mm-dd."""
    if not date_str:
        return ""
    # Handle both date and datetime formats
    if 'T' in date_str:
        return date_str.split('T')[0]
    return date_str


def format_task_metadata(task, labels_dict):
    """Format all task metadata in the specified order."""
    parts = []

    # Priority first
    priority = format_priority(task.get('priority'))
    if priority:
        parts.append(priority)

    # Task content
    parts.append(task['content'])

    # Labels
    labels = format_labels(task.get('labels', []))
    if labels:
        parts.append(labels)

    # Created date
    created = task.get('added_at')
    if created:
        parts.append(f"created:{format_date(created)}")

    # Due date
    due_date = task.get('due')
    if due_date and due_date.get('date'):
        parts.append(f"due:{format_date(due_date['date'])}")

    # Deadline
    deadline = task.get('deadline')
    if deadline and deadline.get('date'):
        parts.append(f"deadline:{format_date(deadline['date'])}")

    # Recurrence
    if due_date and due_date.get('string') and 'every' in due_date.get('string', '').lower():
        parts.append(f"recurs:'{due_date['string']}'")

    # Todoist URL
    task_id = task.get('id')
    if task_id:
        parts.append(f"| [Todoist](https://app.todoist.com/app/task/{task_id})")

    return " ".join(parts)


def format_task_content(content):
    """Format task content, preserving raw content as in Todoist editor."""
    return content


def is_image_file(file_name):
    """Check if a file is an image based on its extension."""
    if not file_name:
        return False

    image_extensions = {'.jpg', '.jpeg', '.png', '.gif', '.bmp', '.svg', '.webp'}
    extension = '.' + file_name.split('.')[-1].lower() if '.' in file_name else ''
    return extension in image_extensions


def download_image(url, file_name, token):
    """Download an image file to the attachments directory."""
    # Create attachments directory if it doesn't exist
    attachments_dir = "attachments"
    os.makedirs(attachments_dir, exist_ok=True)

    # Create a unique filename to avoid conflicts
    name_hash = hashlib.md5(url.encode()).hexdigest()[:8]
    base_name, extension = os.path.splitext(file_name)
    if not extension:
        extension = '.png'  # Default extension if none provided

    local_filename = f"{base_name}_{name_hash}{extension}"
    local_path = os.path.join(attachments_dir, local_filename)

    # Skip download if file already exists
    if os.path.exists(local_path):
        return local_path

    try:
        print(f"Downloading image: {url}", file=sys.stderr)
        # Create request with authorization
        req = Request(url)
        req.add_header('Authorization', f'Bearer {token}')
        req.add_header('User-Agent', 'bob.whitelock1@gmail.com')

        with urlopen(req) as response:
            with open(local_path, 'wb') as f:
                f.write(response.read())

        print(f"Downloaded image: {local_path}", file=sys.stderr)
        return local_path

    except HTTPError as e:
        if e.code == 429:
            retry_after = e.headers.get('Retry-After')
            if retry_after:
                print(f"Failed to download image {url}: Rate limit exceeded (429). Retry after {retry_after} seconds.", file=sys.stderr)
            else:
                print(f"Failed to download image {url}: Rate limit exceeded (429). No retry-after header provided.", file=sys.stderr)
        else:
            print(f"Failed to download image {url}: HTTP Error {e.code}: {e.reason}", file=sys.stderr)
        # Return original URL if download fails
        return url
    except Exception as e:
        print(f"Failed to download image {url}: {e}", file=sys.stderr)
        # Return original URL if download fails
        return url


def format_attachment_url(attachment, token):
    """Format attachment as a Todoist link or image markdown."""
    file_name = attachment.get('file_name', 'attachment')
    file_url = attachment.get('file_url', '')

    # If we have a direct file URL, use that; otherwise construct a Todoist link
    if file_url and file_url.startswith('http'):
        attachment_url = file_url
    else:
        attachment_url = f"https://todoist.com/app/attachment/{attachment.get('resource_type', 'file')}/{file_url or file_name}"

    # If it's an image, download it and format as markdown image
    if is_image_file(file_name):
        local_path = download_image(attachment_url, file_name, token)
        return f"![{file_name}]({local_path})"
    else:
        return attachment_url


def print_tasks_markdown(tasks, token, indent_level=0, file=None):
    """Print tasks in markdown format with proper hierarchy."""
    if file is None:
        file = sys.stdout

    indent = "  " * indent_level

    for task in tasks:
        # Print the main task with all metadata
        task_line = format_task_metadata(task, {})  # Pass empty dict since we don't use it anymore
        print(f"{indent}- {task_line}", file=file)

        # If task has a description, print it as its own bullet point
        # In v1 API, descriptions might be in a different field or format
        description = task.get('description', '') or task.get('note', '')
        if description:
            print(f"{indent}  - description: {description}", file=file)

        # Print comments for this task
        if task.get('comments'):
            for comment in task['comments']:
                comment_content = comment.get('content', '')
                if comment_content:
                    print(f"{indent}  - comment: {comment_content}", file=file)

                    # Handle attachments in comments as their own bullet point
                    attachment = comment.get('file_attachment')
                    if attachment:
                        attachment_url = format_attachment_url(attachment, token)
                        print(f"{indent}    - attachment: {attachment_url}", file=file)

        # Recursively print children
        if task['children']:
            print_tasks_markdown(task['children'], token, indent_level + 1, file=file)


def get_all_projects(token):
    """Get all projects and build hierarchy."""
    sync_data = make_sync_request(['projects'], token)
    projects = sync_data.get('projects', [])

    # Build project hierarchy
    project_dict = {p['id']: p for p in projects}
    root_projects = []

    # Add children lists to each project
    for project in projects:
        project['children'] = []

    # Build the hierarchy
    for project in projects:
        if project.get('parent_id'):
            parent = project_dict.get(project['parent_id'])
            if parent:
                parent['children'].append(project)
        else:
            root_projects.append(project)

    return root_projects


def sanitize_filename(name):
    """Sanitize a project name for use as a filename."""
    # Replace problematic characters with safe alternatives
    return "".join(c if c.isalnum() or c in (' ', '-', '_') else '_' for c in name).strip()


def export_project_to_file(project, token, all_tasks, all_comments, all_labels, all_sections, base_path=""):
    """Export a single project to a markdown file."""
    # Filter tasks, comments, labels, and sections for this project
    tasks, comments, labels, sections = filter_project_tasks_and_comments(
        project['id'], all_tasks, all_comments, all_labels, all_sections)

    # Build label lookup dictionary
    labels_dict = {label['id']: label for label in labels}

    # Build task hierarchy organized by sections
    sections_with_tasks, tasks_without_section = build_task_hierarchy(tasks, comments, sections)

    # Create the file path
    filename = f"{sanitize_filename(project['name'])}.md"
    filepath = os.path.join(base_path, filename) if base_path else filename

    # Ensure directory exists
    if base_path:
        os.makedirs(base_path, exist_ok=True)

    # Write to file
    with open(filepath, 'w', encoding='utf-8') as f:
        # Print tasks without sections first
        if tasks_without_section:
            print_tasks_markdown(tasks_without_section, token, file=f)

        # Print sections with their tasks
        for section_name, section_tasks in sections_with_tasks.items():
            if section_tasks:  # Only print section if it has tasks
                print(f"\n# {section_name}\n", file=f)
                print_tasks_markdown(section_tasks, token, file=f)

    return filepath


def flatten_projects_with_paths(projects, base_path=""):
    """Flatten project hierarchy into list of (project, path) tuples."""
    result = []
    for project in projects:
        # Add this project
        result.append((project, base_path))

        # If project has children, add them recursively in subdirectory
        if project['children']:
            subdir_name = sanitize_filename(project['name'])
            subdir_path = os.path.join(base_path, subdir_name) if base_path else subdir_name
            result.extend(flatten_projects_with_paths(project['children'], subdir_path))

    return result


def export_all_projects(root_projects, token, max_workers=4):
    """Export all projects in parallel to directory hierarchy."""
    # Get all tasks, comments, labels, and sections once upfront
    all_tasks, all_comments, all_labels, all_sections = get_all_tasks_and_comments(token)

    # Flatten the hierarchy to get all projects with their paths
    projects_with_paths = flatten_projects_with_paths(root_projects)
    total_projects = len(projects_with_paths)

    # Export projects in parallel (for image downloads and file writing)
    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        # Submit all export tasks with project info for tracking
        future_to_project = {}
        for project, path in projects_with_paths:
            future = executor.submit(export_project_to_file, project, token, all_tasks, all_comments, all_labels, all_sections, path)
            future_to_project[future] = project

        # Wait for all exports to complete and track progress
        completed = 0
        for future in as_completed(future_to_project):
            completed += 1
            project = future_to_project[future]

            try:
                filepath = future.result()  # This will raise any exceptions that occurred
                filename = os.path.basename(filepath)
                print(f"Exported {completed}/{total_projects}: {filename}", file=sys.stderr)
            except Exception as e:
                print(f"Error exporting project {project['name']}: {e}", file=sys.stderr)


def main():
    # Get API token
    token = get_todoist_api_token()

    # Export all projects to directory hierarchy
    root_projects = get_all_projects(token)
    export_all_projects(root_projects, token)


if __name__ == "__main__":
    main()
