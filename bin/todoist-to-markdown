#!/usr/bin/env python3

import os
import sys
import json
from urllib.request import Request, urlopen
from urllib.parse import urlencode
from urllib.error import URLError, HTTPError
import hashlib
from concurrent.futures import ThreadPoolExecutor, as_completed

# TODO BW 2025-09-20: Comments (and maybe descriptions?) are handled badly,
# multiline content will start on one line but then appear as if it is a new
# task/section on subsequent lines
# TODO BW 2025-09-20: If an attachment fails to attach, this script ends up
# downloading the Todoist login page for that attachment instead.
# TODO BW 2025-10-02: Include a pipe between task content and all metadata, so
# can easily copy just the content by yanking until the pipe?
# TODO BW 2025-10-02: The only actually forbidden character in filenames on
# Linux is `/`, so just allow everything else to preserve project names? And
# maybe switch that to `\`?

def get_todoist_api_token():
    """Get the Todoist API token from environment variable."""
    token = os.environ.get('TODOIST_API_TOKEN')
    if not token:
        print("Error: TODOIST_API_TOKEN environment variable not set", file=sys.stderr)
        sys.exit(1)
    return token


def make_sync_request(resource_types, token):
    """Make a sync request to the Todoist API v1."""
    url = "https://api.todoist.com/api/v1/sync"
    data = urlencode({
        'sync_token': '*',
        'resource_types': json.dumps(resource_types)
    })

    req = Request(url, data.encode('utf-8'))
    req.add_header('Authorization', f'Bearer {token}')
    req.add_header('Content-Type', 'application/x-www-form-urlencoded')
    req.add_header('User-Agent', 'bob.whitelock1@gmail.com')

    try:
        with urlopen(req) as response:
            return json.loads(response.read().decode('utf-8'))
    except HTTPError as e:
        if e.code == 429:
            retry_after = e.headers.get('Retry-After')
            if retry_after:
                print(f"Rate limit exceeded (429). Retry after {retry_after} seconds.", file=sys.stderr)
            else:
                print("Rate limit exceeded (429). No retry-after header provided.", file=sys.stderr)
        else:
            print(f"HTTP Error {e.code}: {e.reason}", file=sys.stderr)
        sys.exit(1)
    except URLError as e:
        print(f"URL Error: {e.reason}", file=sys.stderr)
        sys.exit(1)
    except json.JSONDecodeError as e:
        print(f"JSON decode error: {e}", file=sys.stderr)
        sys.exit(1)



def get_all_tasks_and_comments(token):
    """Get all tasks, comments, labels, and sections from Todoist."""
    print("Getting all tasks, comments, labels, and sections...", file=sys.stderr)
    sync_data = make_sync_request(['items', 'notes', 'labels', 'sections'], token)
    all_tasks = sync_data.get('items', [])
    all_comments = sync_data.get('notes', [])
    all_labels = sync_data.get('labels', [])
    all_sections = sync_data.get('sections', [])
    return all_tasks, all_comments, all_labels, all_sections


def filter_project_tasks_and_comments(project_id, all_tasks, all_comments, all_labels, all_sections):
    """Filter tasks, comments, labels, and sections for a specific project from pre-fetched data."""
    # Filter tasks for the specific project
    project_tasks = [task for task in all_tasks if task['project_id'] == project_id]

    # Filter comments for tasks in this project
    task_ids = {task['id'] for task in project_tasks}
    project_comments = [comment for comment in all_comments if comment.get('item_id') in task_ids]

    # Filter sections for this project
    project_sections = [section for section in all_sections if section['project_id'] == project_id]

    return project_tasks, project_comments, all_labels, project_sections


def build_task_hierarchy(tasks, comments, sections):
    """Build a hierarchical structure of tasks with comments, organized by sections."""
    task_dict = {task['id']: task for task in tasks}
    section_dict = {section['id']: section for section in sections}

    # Add children and comments lists to each task
    for task in tasks:
        task['children'] = []
        task['comments'] = []

    # Associate comments with tasks
    for comment in comments:
        item_id = comment.get('item_id')
        if item_id and item_id in task_dict:
            task_dict[item_id]['comments'].append(comment)

    # Build the hierarchy
    root_tasks = []
    for task in tasks:
        if task.get('parent_id'):
            parent = task_dict.get(task['parent_id'])
            if parent:
                parent['children'].append(task)
        else:
            root_tasks.append(task)

    # Group root tasks by section
    sections_with_tasks = {}
    tasks_without_section = []

    for task in root_tasks:
        section_id = task.get('section_id')
        if section_id and section_id in section_dict:
            section_name = section_dict[section_id]['name']
            if section_name not in sections_with_tasks:
                sections_with_tasks[section_name] = []
            sections_with_tasks[section_name].append(task)
        else:
            tasks_without_section.append(task)

    return sections_with_tasks, tasks_without_section


def format_date(date_str):
    if not date_str:
        return ""
    if 'T' in date_str:
        return date_str.split('T')[0]
    return date_str


def format_task_metadata_bullets(task):
    bullets = []

    task_id = task.get('id')
    if task_id:
        bullets.append(f"- URL: https://app.todoist.com/app/task/{task_id}")

    priority = task.get('priority')
    if priority and priority > 1:
        bullets.append(f"- Priority: !!{priority}")

    due_date = task.get('due')
    if due_date and due_date.get('date'):
        bullets.append(f"- Due: {format_date(due_date['date'])}")

    deadline = task.get('deadline')
    if deadline and deadline.get('date'):
        bullets.append(f"- Deadline: {format_date(deadline['date'])}")

    if due_date and due_date.get('string') and 'every' in due_date.get('string', '').lower():
        bullets.append(f"- Recurring: '{due_date['string']}'")

    label_names = task.get('labels', [])
    if label_names:
        labels = " ".join(f"@{label}" for label in label_names)
        bullets.append(f"- Labels: {labels}")

    return bullets


def is_image_file(file_name):
    """Check if a file is an image based on its extension."""
    if not file_name:
        return False

    image_extensions = {'.jpg', '.jpeg', '.png', '.gif', '.bmp', '.svg', '.webp'}
    extension = '.' + file_name.split('.')[-1].lower() if '.' in file_name else ''
    return extension in image_extensions


def download_image(url, file_name, token, output_root="", current_dir=""):
    """Download an image file to the attachments directory and return relative path."""
    # Create attachments directory in the output root
    attachments_dir = os.path.join(output_root, "attachments") if output_root else "attachments"
    os.makedirs(attachments_dir, exist_ok=True)

    # Create a unique filename to avoid conflicts
    name_hash = hashlib.md5(url.encode()).hexdigest()[:8]
    base_name, extension = os.path.splitext(file_name)
    if not extension:
        extension = '.png'  # Default extension if none provided

    local_filename = f"{base_name}_{name_hash}{extension}"
    local_path = os.path.join(attachments_dir, local_filename)

    # Skip download if file already exists
    if os.path.exists(local_path):
        # Return relative path from current directory to the existing image
        if current_dir and output_root:
            relative_path = os.path.relpath(local_path, current_dir)
            return relative_path
        return local_path

    try:
        print(f"Downloading image: {url}", file=sys.stderr)
        # Create request with authorization
        req = Request(url)
        req.add_header('Authorization', f'Bearer {token}')
        req.add_header('User-Agent', 'bob.whitelock1@gmail.com')

        with urlopen(req) as response:
            with open(local_path, 'wb') as f:
                f.write(response.read())

        print(f"Downloaded image: {local_path}", file=sys.stderr)
        # Return relative path from current directory to the downloaded image
        if current_dir and output_root:
            relative_path = os.path.relpath(local_path, current_dir)
            return relative_path
        return local_path

    except HTTPError as e:
        if e.code == 429:
            retry_after = e.headers.get('Retry-After')
            if retry_after:
                print(f"Failed to download image {url}: Rate limit exceeded (429). Retry after {retry_after} seconds.", file=sys.stderr)
            else:
                print(f"Failed to download image {url}: Rate limit exceeded (429). No retry-after header provided.", file=sys.stderr)
        else:
            print(f"Failed to download image {url}: HTTP Error {e.code}: {e.reason}", file=sys.stderr)
        # Return original URL if download fails
        return url
    except Exception as e:
        print(f"Failed to download image {url}: {e}", file=sys.stderr)
        # Return original URL if download fails
        return url


def format_attachment_url(attachment, token, output_root="", current_dir=""):
    """Format attachment as a Todoist link or image markdown."""
    file_name = attachment.get('file_name', 'attachment')
    file_url = attachment.get('file_url', '')
    resource_type = attachment.get('resource_type', 'file')

    if resource_type == 'website':
        return file_name or file_url or ''

    if file_url and file_url.startswith('http'):
        attachment_url = file_url
    else:
        attachment_url = f"https://todoist.com/app/attachment/{resource_type}/{file_url or file_name}"

    if is_image_file(file_name):
        local_path = download_image(attachment_url, file_name, token, output_root, current_dir)
        return f"![{file_name}]({local_path})"
    else:
        return attachment_url


def print_tasks_markdown(tasks, token, indent_level=0, file=None, output_root="", current_dir=""):
    if file is None:
        file = sys.stdout

    i0 = "  " * indent_level
    i1 = "  " * (indent_level + 1)
    i2 = "  " * (indent_level + 2)
    i3 = "  " * (indent_level + 3)

    for task in tasks:
        content = task['content'].replace('\n', ' ')
        print(f"{i0}- {content}", file=file)

        for bullet in format_task_metadata_bullets(task):
            print(f"{i1}{bullet}", file=file)

        description = (task.get('description', '') or task.get('note', '')).strip()
        if description:
            print(f"{i1}- Description", file=file)
            for line in description.split('\n'):
                print(f"{i2}> {line}", file=file)

        if task.get('comments'):
            has_content = any(c.get('content', '') for c in task['comments'])
            if has_content:
                print(f"{i1}- Comments", file=file)
                for comment in task['comments']:
                    comment_content = comment.get('content', '')
                    if comment_content:
                        lines = comment_content.split('\n')
                        print(f"{i2}- > {lines[0]}", file=file)
                        for line in lines[1:]:
                            print(f"{i2}  > {line}", file=file)
                        attachment = comment.get('file_attachment')
                        if attachment:
                            attachment_url = format_attachment_url(attachment, token, output_root, current_dir)
                            print(f"{i2}  {attachment_url}", file=file)

        if task['children']:
            print(f"{i1}- Sub-tasks", file=file)
            print_tasks_markdown(task['children'], token, indent_level + 2, file=file, output_root=output_root, current_dir=current_dir)


def get_all_projects(token):
    """Get all projects and build hierarchy."""
    sync_data = make_sync_request(['projects'], token)
    projects = sync_data.get('projects', [])

    # Build project hierarchy
    project_dict = {p['id']: p for p in projects}
    root_projects = []

    # Add children lists to each project
    for project in projects:
        project['children'] = []

    # Build the hierarchy
    for project in projects:
        if project.get('parent_id'):
            parent = project_dict.get(project['parent_id'])
            if parent:
                parent['children'].append(project)
        else:
            root_projects.append(project)

    return root_projects


def sanitize_filename(name):
    """Sanitize a project name for use as a filename."""
    # Replace problematic filesystem characters with safe alternatives, but preserve emojis and Unicode
    problematic_chars = '<>:"/\\|?*'
    return "".join('_' if c in problematic_chars else c for c in name).strip()


def export_project_to_file(project, token, all_tasks, all_comments, all_labels, all_sections, base_path="", output_root=""):
    """Export a single project to a markdown file."""
    # Filter tasks, comments, labels, and sections for this project
    tasks, comments, labels, sections = filter_project_tasks_and_comments(
        project['id'], all_tasks, all_comments, all_labels, all_sections)

    # Skip creating markdown file if project has no tasks but has child projects
    if not tasks and project.get('children'):
        return None

    # Build task hierarchy organized by sections
    sections_with_tasks, tasks_without_section = build_task_hierarchy(tasks, comments, sections)

    # Create the file path
    filename = f"{sanitize_filename(project['name'])}.md"
    filepath = os.path.join(base_path, filename) if base_path else filename

    # Ensure directory exists
    if base_path:
        os.makedirs(base_path, exist_ok=True)

    # Write to file
    with open(filepath, 'w', encoding='utf-8') as f:
        # Print tasks without sections first
        if tasks_without_section:
            print_tasks_markdown(tasks_without_section, token, file=f, output_root=output_root, current_dir=base_path)

        # Print sections with their tasks
        for section_name, section_tasks in sections_with_tasks.items():
            if section_tasks:  # Only print section if it has tasks
                print(f"\n# {section_name}\n", file=f)
                print_tasks_markdown(section_tasks, token, file=f, output_root=output_root, current_dir=base_path)

    return filepath


def flatten_projects_with_paths(projects, base_path=""):
    """Flatten project hierarchy into list of (project, path) tuples."""
    result = []
    for project in projects:
        # Add this project
        result.append((project, base_path))

        # If project has children, add them recursively in subdirectory
        if project['children']:
            subdir_name = sanitize_filename(project['name'])
            subdir_path = os.path.join(base_path, subdir_name) if base_path else subdir_name
            result.extend(flatten_projects_with_paths(project['children'], subdir_path))

    return result


def export_all_projects(root_projects, token, base_dir="", max_workers=4):
    """Export all projects in parallel to directory hierarchy."""
    # Get all tasks, comments, labels, and sections once upfront
    all_tasks, all_comments, all_labels, all_sections = get_all_tasks_and_comments(token)

    # Flatten the hierarchy to get all projects with their paths
    projects_with_paths = flatten_projects_with_paths(root_projects, base_dir)
    total_projects = len(projects_with_paths)

    # Export projects in parallel (for image downloads and file writing)
    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        # Submit all export tasks with project info for tracking
        future_to_project = {}
        for project, path in projects_with_paths:
            future = executor.submit(export_project_to_file, project, token, all_tasks, all_comments, all_labels, all_sections, path, base_dir)
            future_to_project[future] = project

        # Wait for all exports to complete and track progress
        completed = 0
        for future in as_completed(future_to_project):
            completed += 1
            project = future_to_project[future]

            try:
                filepath = future.result()  # This will raise any exceptions that occurred
                if filepath:  # Only report if a file was actually created
                    filename = os.path.basename(filepath)
                    print(f"Exported {completed}/{total_projects}: {filename}", file=sys.stderr)
                else:
                    print(f"Skipped {completed}/{total_projects}: {project['name']} (no tasks, has child projects)", file=sys.stderr)
            except Exception as e:
                print(f"Error exporting project {project['name']}: {e}", file=sys.stderr)


def main():
    # Check for directory argument
    if len(sys.argv) != 2:
        print("Usage: todoist-to-markdown <directory>", file=sys.stderr)
        print("Exports all Todoist projects to markdown files under the specified directory", file=sys.stderr)
        sys.exit(1)

    output_dir = sys.argv[1]

    # Get API token
    token = get_todoist_api_token()

    # Export all projects to directory hierarchy under the specified directory
    root_projects = get_all_projects(token)
    export_all_projects(root_projects, token, output_dir)


if __name__ == "__main__":
    main()
